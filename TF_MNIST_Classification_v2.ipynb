{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_MNIST_Classification_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo2JiEtkzvQL"
      },
      "source": [
        "# Digit Classification using Dense Neural Network (DNN) - Version 2 \n",
        " - Using validation and test data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLLenukpg6VN"
      },
      "source": [
        "## ==> Verify on Runtime tab if GPU is active on Runtime type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z56YN3JZ0Duh"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfPnR74Gzc_q"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrGLDV6q0PCc"
      },
      "source": [
        "## Upload and Explore Dataset\n",
        "[MNIST](http://yann.lecun.com/exdb/mnist/) handwritten digits dataset\n",
        "\n",
        "The MNIST database of handwritten digits, is also available from this [TF page](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data), has a training set of 60,000 28x28 grayscale images of the 10 digits along a test set of 10,000 images. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib2Ihepx0N6h"
      },
      "source": [
        "data = tf.keras.datasets.mnist\n",
        "\n",
        "(tt_images, tt_labels), (test_images, test_labels) = data.load_data()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78pNLabSX-LF"
      },
      "source": [
        "print(tt_images.shape)\n",
        "print(tt_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHaUYnSs4bq4"
      },
      "source": [
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzQgqFXcXSba"
      },
      "source": [
        "tt_labels[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEmBmJqGYMpv"
      },
      "source": [
        "plt.hist(tt_labels);\n",
        "plt.hist(test_labels);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_e88OtBak7n"
      },
      "source": [
        "val_images = tt_images[:10000]\n",
        "val_labels = tt_labels[:10000]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtTSlX3TaDqj"
      },
      "source": [
        "train_images = tt_images[10000:]\n",
        "train_labels = tt_labels[10000:]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq1bMIRd38b8"
      },
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj2dTT44awxD"
      },
      "source": [
        "print(val_images.shape)\n",
        "print(val_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N4sFgGLaXYQ"
      },
      "source": [
        "plt.hist(train_labels, alpha=0.5, label='Train')\n",
        "plt.hist(test_labels, alpha=0.5, label='Val')\n",
        "plt.hist(val_labels, alpha=0.5, label='Test');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyaS6AgJd9_q"
      },
      "source": [
        "img = 1000\n",
        "print(\"     Label of image {} is: {}\".format(img, test_labels[img]))\n",
        "plt.imshow(test_images[img], cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-H0LwB_7von"
      },
      "source": [
        "### Preprocessing Data \n",
        "\n",
        "**Normalizing Data**: \n",
        "We notice that all of the values in the number are between 0 and 255. If we are training a neural network, for various reasons it's easier if we treat all values as between 0 and 1, a process called 'normalizing'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZrGVMsH0X3F"
      },
      "source": [
        "train_images  = train_images / 255.0\n",
        "val_images = val_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYMsyOk8-xnf"
      },
      "source": [
        "## Define and Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEdoqWl28dB3"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr_eCKjGbtOt"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJz_2NgwcIiZ"
      },
      "source": [
        "model = Sequential([Flatten(input_shape=(28,28)),\n",
        "                    Dense(20, activation='relu'),\n",
        "                    Dense(10, activation='softmax')])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECBeHUKacZ_4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "#model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQjO9CvIbdar"
      },
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=(28,28)))\n",
        "  model.add(Dense(20, activation='relu'))\n",
        "  model.add(Dense(10, activation='softmax')) \n",
        "  return model "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X920NSLjbsNp"
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA21O9Y0_BJ7"
      },
      "source": [
        "model.compile(\n",
        "    optimizer='adam', # uses default learning_rate=0.001\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7BSHPohdZ-Y"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_d2yHsqf_JI"
      },
      "source": [
        "opt = Adam(learning_rate=0.01)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJZ4fvT3_yd7"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL6QDHJnGDm6"
      },
      "source": [
        "You could leave the training data with all samples, and alternativelly use: \n",
        "- `validation_split=0.1` instead of `validation_data=(val_images, val_labels)`.\n",
        "\n",
        "In this case, TF will split the validation data by itself. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxklrX_R_uvn"
      },
      "source": [
        "history = model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    epochs=20, \n",
        "    validation_data=(val_images, val_labels) \n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xAXSo5-HCIo"
      },
      "source": [
        "Inspecting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6qHpwg8BpZi"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF1jssVyel8D"
      },
      "source": [
        "If validation accuracy seems “instable”, could be that Learning Rate is high (try to reduce it). \n",
        "\n",
        "Let's start over with a lower Lr (for exampe: 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21HE2qcnbMCf"
      },
      "source": [
        "opt = Adam(learning_rate=0.001)\n",
        "\n",
        "model = create_model()\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "history = model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    epochs=20, \n",
        "    validation_data=(val_images, val_labels) \n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYlZ1ZNrcrGC"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYHTdEJVH0tZ"
      },
      "source": [
        "## Testing the trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBuJGqbSH6xT"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVZcgwAQHZMl"
      },
      "source": [
        "**Accuracy**\n",
        "- Train: 0.97; \n",
        "- Validation: 0.96 \n",
        "- Test: 0.95"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvNEv5BPIwPE"
      },
      "source": [
        "plt.imshow(test_images[0]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysGu1V_PJ28-"
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkaTLMaTIbIL"
      },
      "source": [
        "predictions = model.predict(test_images)\n",
        "print(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjenS2EZJH6h"
      },
      "source": [
        "# Returns the indices of the maximum values along an axis.\n",
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeEgVvBTIx8z"
      },
      "source": [
        "predictions = np.argmax(predictions, axis=-1)\n",
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N2zUFaZJIUF"
      },
      "source": [
        "predictions[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP0iVCbHHzDI"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "print(classification_report(test_labels, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqQ4K-KqJYWe"
      },
      "source": [
        "confusion_matrix(test_labels,predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaXyFJffLLLY"
      },
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.heatmap(confusion_matrix(test_labels,predictions), cmap=\"Blues\", annot=True, fmt='g');\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Real values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1PyVPkhRx01"
      },
      "source": [
        "model.save('MNIST_v2_model.h5')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "754rc-kPR7zH"
      },
      "source": [
        "Use [Netron](https://netron.app) to visualize the model, hyperparameters, tensor shapes, etc. Netron is a viewer for neural network, deep learning and machine learning models (See [GitHub](https://github.com/lutzroeder/netron) for instructions about instalation in your desktop). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFYKoEpsSCF8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}